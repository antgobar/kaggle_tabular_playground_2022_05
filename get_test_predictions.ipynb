{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helpers.helper_functions import load_data, get_scaled_data\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data('data')\n",
    "X_train, y_train = pd.read_csv('data/X_prepped.csv', index_col = 'id'), train.target\n",
    "X_test = get_scaled_data(test.reset_index(drop = True), is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>10_F</th>\n",
       "      <th>10_G</th>\n",
       "      <th>10_H</th>\n",
       "      <th>10_I</th>\n",
       "      <th>10_J</th>\n",
       "      <th>10_K</th>\n",
       "      <th>10_L</th>\n",
       "      <th>10_M</th>\n",
       "      <th>10_N</th>\n",
       "      <th>10_O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443296</td>\n",
       "      <td>0.173355</td>\n",
       "      <td>-1.000476</td>\n",
       "      <td>0.763976</td>\n",
       "      <td>0.187318</td>\n",
       "      <td>-1.075194</td>\n",
       "      <td>0.502626</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.605986</td>\n",
       "      <td>-0.307128</td>\n",
       "      <td>0.626171</td>\n",
       "      <td>-0.577429</td>\n",
       "      <td>-1.750070</td>\n",
       "      <td>1.355436</td>\n",
       "      <td>-0.190213</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304615</td>\n",
       "      <td>2.445921</td>\n",
       "      <td>0.245214</td>\n",
       "      <td>0.819474</td>\n",
       "      <td>0.360241</td>\n",
       "      <td>-1.332297</td>\n",
       "      <td>1.359411</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.154511</td>\n",
       "      <td>0.259170</td>\n",
       "      <td>-1.367563</td>\n",
       "      <td>-0.091791</td>\n",
       "      <td>-1.110279</td>\n",
       "      <td>-0.948885</td>\n",
       "      <td>1.119995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.653458</td>\n",
       "      <td>-0.425775</td>\n",
       "      <td>-0.668187</td>\n",
       "      <td>-0.320700</td>\n",
       "      <td>-0.088877</td>\n",
       "      <td>0.181443</td>\n",
       "      <td>1.785797</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  f_07  \\\n",
       "0  0.443296  0.173355 -1.000476  0.763976  0.187318 -1.075194  0.502626     6   \n",
       "1 -0.605986 -0.307128  0.626171 -0.577429 -1.750070  1.355436 -0.190213     1   \n",
       "2  0.304615  2.445921  0.245214  0.819474  0.360241 -1.332297  1.359411     3   \n",
       "3  0.154511  0.259170 -1.367563 -0.091791 -1.110279 -0.948885  1.119995     0   \n",
       "4 -1.653458 -0.425775 -0.668187 -0.320700 -0.088877  0.181443  1.785797     2   \n",
       "\n",
       "   f_08  f_09  ...  10_F  10_G  10_H  10_I  10_J  10_K  10_L  10_M  10_N  10_O  \n",
       "0     6     0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     3     4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2     3     4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     0     4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     2     2  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>10_F</th>\n",
       "      <th>10_G</th>\n",
       "      <th>10_H</th>\n",
       "      <th>10_I</th>\n",
       "      <th>10_J</th>\n",
       "      <th>10_K</th>\n",
       "      <th>10_L</th>\n",
       "      <th>10_M</th>\n",
       "      <th>10_N</th>\n",
       "      <th>10_O</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.374490</td>\n",
       "      <td>0.237914</td>\n",
       "      <td>-0.244425</td>\n",
       "      <td>0.568674</td>\n",
       "      <td>-0.647037</td>\n",
       "      <td>0.839148</td>\n",
       "      <td>0.113849</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.699197</td>\n",
       "      <td>-1.712872</td>\n",
       "      <td>-2.230360</td>\n",
       "      <td>-0.544198</td>\n",
       "      <td>1.113558</td>\n",
       "      <td>-1.552654</td>\n",
       "      <td>0.448561</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.683885</td>\n",
       "      <td>0.616078</td>\n",
       "      <td>-1.028335</td>\n",
       "      <td>0.811719</td>\n",
       "      <td>-0.608415</td>\n",
       "      <td>0.113695</td>\n",
       "      <td>-0.707992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118017</td>\n",
       "      <td>-0.589476</td>\n",
       "      <td>-0.805398</td>\n",
       "      <td>2.087827</td>\n",
       "      <td>0.371515</td>\n",
       "      <td>-0.129132</td>\n",
       "      <td>-0.281882</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.150047</td>\n",
       "      <td>-0.177876</td>\n",
       "      <td>-0.665703</td>\n",
       "      <td>-1.099783</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.499896</td>\n",
       "      <td>0.408249</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "id                                                                         \n",
       "0  -1.374490  0.237914 -0.244425  0.568674 -0.647037  0.839148  0.113849   \n",
       "1   1.699197 -1.712872 -2.230360 -0.544198  1.113558 -1.552654  0.448561   \n",
       "2   1.683885  0.616078 -1.028335  0.811719 -0.608415  0.113695 -0.707992   \n",
       "3  -0.118017 -0.589476 -0.805398  2.087827  0.371515 -0.129132 -0.281882   \n",
       "4   1.150047 -0.177876 -0.665703 -1.099783  0.468368  0.499896  0.408249   \n",
       "\n",
       "    f_07  f_08  f_09  ...  10_F  10_G  10_H  10_I  10_J  10_K  10_L  10_M  \\\n",
       "id                    ...                                                   \n",
       "0      1     5     1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1      1     3     4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2      1     0     2  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3      3     2     1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4      3     3     0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    10_N  10_O  \n",
       "id              \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from helpers.train_helpers import BATCH_SIZE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SHAPE = X_test.shape[1]\n",
    "model_3 = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(100, activation=\"swish\", input_dim = INPUT_SHAPE),\n",
    "        keras.layers.Dense(50, activation=\"swish\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"Dense_model_3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictor(model_in, X_train, y_train, X_test, n_folds = 5):\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "                    patience=20, monitor=\"val_loss\", restore_best_weights=True, verbose = 1\n",
    "                )\n",
    "    learn_reducer = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, patience = 5, verbose = 1)\n",
    "    kf = KFold(n_folds)\n",
    "    store = []\n",
    "\n",
    "    model_in.summary()\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(\n",
    "        kf.split(X_train)\n",
    "    ):\n",
    "        \n",
    "        print(f\"Fitting fold {fold} for {model_in.name}...\")\n",
    "        model = keras.models.clone_model(model_in)\n",
    "        model.compile(\n",
    "            optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC()]\n",
    "        )\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[\n",
    "                early_stopping, learn_reducer\n",
    "            ],\n",
    "        )\n",
    "        auc = roc_auc_score(y_val, model.predict(X_val).squeeze())\n",
    "        print(f\"The val auc for fold {fold}, {model_in.name} is {auc}\")\n",
    "        store.append(model.predict(X_test).squeeze())\n",
    "\n",
    "    result = sum(store) / n_folds \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               14800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,901\n",
      "Trainable params: 19,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fitting fold 0 for Dense_model_3...\n",
      "Epoch 1/400\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 0.4220 - auc_2: 0.8935 - val_loss: 0.3270 - val_auc_2: 0.9380 - lr: 0.0010\n",
      "Epoch 2/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3144 - auc_2: 0.9423 - val_loss: 0.3016 - val_auc_2: 0.9466 - lr: 0.0010\n",
      "Epoch 3/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2917 - auc_2: 0.9491 - val_loss: 0.2830 - val_auc_2: 0.9520 - lr: 0.0010\n",
      "Epoch 4/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2742 - auc_2: 0.9541 - val_loss: 0.2671 - val_auc_2: 0.9565 - lr: 0.0010\n",
      "Epoch 5/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2600 - auc_2: 0.9584 - val_loss: 0.2568 - val_auc_2: 0.9597 - lr: 0.0010\n",
      "Epoch 6/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2492 - auc_2: 0.9618 - val_loss: 0.2470 - val_auc_2: 0.9625 - lr: 0.0010\n",
      "Epoch 7/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2400 - auc_2: 0.9646 - val_loss: 0.2376 - val_auc_2: 0.9654 - lr: 0.0010\n",
      "Epoch 8/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2321 - auc_2: 0.9669 - val_loss: 0.2302 - val_auc_2: 0.9674 - lr: 0.0010\n",
      "Epoch 9/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2246 - auc_2: 0.9690 - val_loss: 0.2239 - val_auc_2: 0.9692 - lr: 0.0010\n",
      "Epoch 10/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2178 - auc_2: 0.9708 - val_loss: 0.2177 - val_auc_2: 0.9709 - lr: 0.0010\n",
      "Epoch 11/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2105 - auc_2: 0.9727 - val_loss: 0.2114 - val_auc_2: 0.9729 - lr: 0.0010\n",
      "Epoch 12/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2027 - auc_2: 0.9747 - val_loss: 0.2028 - val_auc_2: 0.9747 - lr: 0.0010\n",
      "Epoch 13/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1943 - auc_2: 0.9768 - val_loss: 0.1959 - val_auc_2: 0.9764 - lr: 0.0010\n",
      "Epoch 14/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1864 - auc_2: 0.9786 - val_loss: 0.1877 - val_auc_2: 0.9783 - lr: 0.0010\n",
      "Epoch 15/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1797 - auc_2: 0.9801 - val_loss: 0.1825 - val_auc_2: 0.9795 - lr: 0.0010\n",
      "Epoch 16/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1739 - auc_2: 0.9813 - val_loss: 0.1758 - val_auc_2: 0.9809 - lr: 0.0010\n",
      "Epoch 17/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1684 - auc_2: 0.9825 - val_loss: 0.1718 - val_auc_2: 0.9820 - lr: 0.0010\n",
      "Epoch 18/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1629 - auc_2: 0.9836 - val_loss: 0.1665 - val_auc_2: 0.9831 - lr: 0.0010\n",
      "Epoch 19/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1574 - auc_2: 0.9847 - val_loss: 0.1608 - val_auc_2: 0.9841 - lr: 0.0010\n",
      "Epoch 20/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1519 - auc_2: 0.9857 - val_loss: 0.1548 - val_auc_2: 0.9851 - lr: 0.0010\n",
      "Epoch 21/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1465 - auc_2: 0.9866 - val_loss: 0.1505 - val_auc_2: 0.9859 - lr: 0.0010\n",
      "Epoch 22/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1410 - auc_2: 0.9876 - val_loss: 0.1445 - val_auc_2: 0.9869 - lr: 0.0010\n",
      "Epoch 23/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1360 - auc_2: 0.9884 - val_loss: 0.1423 - val_auc_2: 0.9875 - lr: 0.0010\n",
      "Epoch 24/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1304 - auc_2: 0.9893 - val_loss: 0.1342 - val_auc_2: 0.9886 - lr: 0.0010\n",
      "Epoch 25/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1254 - auc_2: 0.9900 - val_loss: 0.1292 - val_auc_2: 0.9894 - lr: 0.0010\n",
      "Epoch 26/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1208 - auc_2: 0.9907 - val_loss: 0.1258 - val_auc_2: 0.9900 - lr: 0.0010\n",
      "Epoch 27/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1168 - auc_2: 0.9913 - val_loss: 0.1231 - val_auc_2: 0.9903 - lr: 0.0010\n",
      "Epoch 28/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1134 - auc_2: 0.9917 - val_loss: 0.1196 - val_auc_2: 0.9908 - lr: 0.0010\n",
      "Epoch 29/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1096 - auc_2: 0.9923 - val_loss: 0.1171 - val_auc_2: 0.9911 - lr: 0.0010\n",
      "Epoch 30/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1066 - auc_2: 0.9927 - val_loss: 0.1140 - val_auc_2: 0.9917 - lr: 0.0010\n",
      "Epoch 31/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1034 - auc_2: 0.9931 - val_loss: 0.1169 - val_auc_2: 0.9918 - lr: 0.0010\n",
      "Epoch 32/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1012 - auc_2: 0.9933 - val_loss: 0.1085 - val_auc_2: 0.9923 - lr: 0.0010\n",
      "Epoch 33/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0985 - auc_2: 0.9937 - val_loss: 0.1066 - val_auc_2: 0.9927 - lr: 0.0010\n",
      "Epoch 34/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0965 - auc_2: 0.9939 - val_loss: 0.1059 - val_auc_2: 0.9928 - lr: 0.0010\n",
      "Epoch 35/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0947 - auc_2: 0.9942 - val_loss: 0.1028 - val_auc_2: 0.9931 - lr: 0.0010\n",
      "Epoch 36/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0929 - auc_2: 0.9943 - val_loss: 0.1009 - val_auc_2: 0.9933 - lr: 0.0010\n",
      "Epoch 37/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0910 - auc_2: 0.9945 - val_loss: 0.1015 - val_auc_2: 0.9933 - lr: 0.0010\n",
      "Epoch 38/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0895 - auc_2: 0.9947 - val_loss: 0.0999 - val_auc_2: 0.9937 - lr: 0.0010\n",
      "Epoch 39/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0881 - auc_2: 0.9949 - val_loss: 0.0977 - val_auc_2: 0.9937 - lr: 0.0010\n",
      "Epoch 40/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0867 - auc_2: 0.9950 - val_loss: 0.0976 - val_auc_2: 0.9938 - lr: 0.0010\n",
      "Epoch 41/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0853 - auc_2: 0.9952 - val_loss: 0.0973 - val_auc_2: 0.9939 - lr: 0.0010\n",
      "Epoch 42/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0840 - auc_2: 0.9953 - val_loss: 0.0936 - val_auc_2: 0.9942 - lr: 0.0010\n",
      "Epoch 43/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0825 - auc_2: 0.9955 - val_loss: 0.0937 - val_auc_2: 0.9942 - lr: 0.0010\n",
      "Epoch 44/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0818 - auc_2: 0.9956 - val_loss: 0.0948 - val_auc_2: 0.9942 - lr: 0.0010\n",
      "Epoch 45/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0805 - auc_2: 0.9957 - val_loss: 0.0903 - val_auc_2: 0.9946 - lr: 0.0010\n",
      "Epoch 46/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0794 - auc_2: 0.9958 - val_loss: 0.0898 - val_auc_2: 0.9947 - lr: 0.0010\n",
      "Epoch 47/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0782 - auc_2: 0.9959 - val_loss: 0.0893 - val_auc_2: 0.9947 - lr: 0.0010\n",
      "Epoch 48/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0773 - auc_2: 0.9960 - val_loss: 0.0901 - val_auc_2: 0.9947 - lr: 0.0010\n",
      "Epoch 49/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0765 - auc_2: 0.9961 - val_loss: 0.0893 - val_auc_2: 0.9947 - lr: 0.0010\n",
      "Epoch 50/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0760 - auc_2: 0.9961 - val_loss: 0.0874 - val_auc_2: 0.9949 - lr: 0.0010\n",
      "Epoch 51/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0751 - auc_2: 0.9962 - val_loss: 0.0867 - val_auc_2: 0.9949 - lr: 0.0010\n",
      "Epoch 52/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0745 - auc_2: 0.9963 - val_loss: 0.0866 - val_auc_2: 0.9950 - lr: 0.0010\n",
      "Epoch 53/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0738 - auc_2: 0.9964 - val_loss: 0.0862 - val_auc_2: 0.9950 - lr: 0.0010\n",
      "Epoch 54/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0732 - auc_2: 0.9964 - val_loss: 0.0867 - val_auc_2: 0.9951 - lr: 0.0010\n",
      "Epoch 55/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0727 - auc_2: 0.9964 - val_loss: 0.0864 - val_auc_2: 0.9951 - lr: 0.0010\n",
      "Epoch 56/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0718 - auc_2: 0.9965 - val_loss: 0.0862 - val_auc_2: 0.9951 - lr: 0.0010\n",
      "Epoch 57/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0713 - auc_2: 0.9966 - val_loss: 0.0848 - val_auc_2: 0.9951 - lr: 0.0010\n",
      "Epoch 58/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0706 - auc_2: 0.9966 - val_loss: 0.0844 - val_auc_2: 0.9952 - lr: 0.0010\n",
      "Epoch 59/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0701 - auc_2: 0.9967 - val_loss: 0.0841 - val_auc_2: 0.9952 - lr: 0.0010\n",
      "Epoch 60/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0700 - auc_2: 0.9967 - val_loss: 0.0837 - val_auc_2: 0.9953 - lr: 0.0010\n",
      "Epoch 61/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0696 - auc_2: 0.9967 - val_loss: 0.0832 - val_auc_2: 0.9953 - lr: 0.0010\n",
      "Epoch 62/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0689 - auc_2: 0.9968 - val_loss: 0.0858 - val_auc_2: 0.9951 - lr: 0.0010\n",
      "Epoch 63/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0683 - auc_2: 0.9969 - val_loss: 0.0829 - val_auc_2: 0.9953 - lr: 0.0010\n",
      "Epoch 64/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0679 - auc_2: 0.9969 - val_loss: 0.0836 - val_auc_2: 0.9953 - lr: 0.0010\n",
      "Epoch 65/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0678 - auc_2: 0.9969 - val_loss: 0.0820 - val_auc_2: 0.9954 - lr: 0.0010\n",
      "Epoch 66/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0672 - auc_2: 0.9969 - val_loss: 0.0819 - val_auc_2: 0.9954 - lr: 0.0010\n",
      "Epoch 67/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0670 - auc_2: 0.9970 - val_loss: 0.0815 - val_auc_2: 0.9955 - lr: 0.0010\n",
      "Epoch 68/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0666 - auc_2: 0.9970 - val_loss: 0.0814 - val_auc_2: 0.9955 - lr: 0.0010\n",
      "Epoch 69/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0661 - auc_2: 0.9970 - val_loss: 0.0838 - val_auc_2: 0.9955 - lr: 0.0010\n",
      "Epoch 70/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0660 - auc_2: 0.9970 - val_loss: 0.0814 - val_auc_2: 0.9954 - lr: 0.0010\n",
      "Epoch 71/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0654 - auc_2: 0.9971 - val_loss: 0.0820 - val_auc_2: 0.9954 - lr: 0.0010\n",
      "Epoch 72/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0651 - auc_2: 0.9971 - val_loss: 0.0816 - val_auc_2: 0.9954 - lr: 0.0010\n",
      "Epoch 73/400\n",
      "348/352 [============================>.] - ETA: 0s - loss: 0.0648 - auc_2: 0.9971\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0648 - auc_2: 0.9971 - val_loss: 0.0816 - val_auc_2: 0.9955 - lr: 0.0010\n",
      "Epoch 74/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0631 - auc_2: 0.9973 - val_loss: 0.0803 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 75/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0628 - auc_2: 0.9973 - val_loss: 0.0806 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 76/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0625 - auc_2: 0.9973 - val_loss: 0.0818 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 77/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0624 - auc_2: 0.9973 - val_loss: 0.0801 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 78/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0623 - auc_2: 0.9973 - val_loss: 0.0808 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 79/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0619 - auc_2: 0.9974 - val_loss: 0.0815 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 80/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0619 - auc_2: 0.9974 - val_loss: 0.0816 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 81/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0616 - auc_2: 0.9974 - val_loss: 0.0812 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 82/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0616 - auc_2: 0.9974 - val_loss: 0.0795 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 83/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0613 - auc_2: 0.9974 - val_loss: 0.0796 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 84/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0612 - auc_2: 0.9974 - val_loss: 0.0810 - val_auc_2: 0.9955 - lr: 7.0000e-04\n",
      "Epoch 85/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0607 - auc_2: 0.9975 - val_loss: 0.0794 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 86/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0610 - auc_2: 0.9974 - val_loss: 0.0792 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 87/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0605 - auc_2: 0.9975 - val_loss: 0.0792 - val_auc_2: 0.9957 - lr: 7.0000e-04\n",
      "Epoch 88/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0603 - auc_2: 0.9975 - val_loss: 0.0794 - val_auc_2: 0.9957 - lr: 7.0000e-04\n",
      "Epoch 89/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0603 - auc_2: 0.9975 - val_loss: 0.0797 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 90/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0603 - auc_2: 0.9975 - val_loss: 0.0820 - val_auc_2: 0.9957 - lr: 7.0000e-04\n",
      "Epoch 91/400\n",
      "346/352 [============================>.] - ETA: 0s - loss: 0.0599 - auc_2: 0.9975\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0599 - auc_2: 0.9975 - val_loss: 0.0801 - val_auc_2: 0.9956 - lr: 7.0000e-04\n",
      "Epoch 92/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0586 - auc_2: 0.9976 - val_loss: 0.0789 - val_auc_2: 0.9957 - lr: 4.9000e-04\n",
      "Epoch 93/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0584 - auc_2: 0.9977 - val_loss: 0.0791 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 94/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0584 - auc_2: 0.9976 - val_loss: 0.0811 - val_auc_2: 0.9955 - lr: 4.9000e-04\n",
      "Epoch 95/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0582 - auc_2: 0.9977 - val_loss: 0.0788 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 96/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0581 - auc_2: 0.9977 - val_loss: 0.0787 - val_auc_2: 0.9957 - lr: 4.9000e-04\n",
      "Epoch 97/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0580 - auc_2: 0.9977 - val_loss: 0.0789 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 98/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0580 - auc_2: 0.9977 - val_loss: 0.0806 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 99/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0578 - auc_2: 0.9977 - val_loss: 0.0795 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 100/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0577 - auc_2: 0.9977 - val_loss: 0.0795 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 101/400\n",
      "344/352 [============================>.] - ETA: 0s - loss: 0.0576 - auc_2: 0.9977\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0576 - auc_2: 0.9977 - val_loss: 0.0790 - val_auc_2: 0.9956 - lr: 4.9000e-04\n",
      "Epoch 102/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0566 - auc_2: 0.9978 - val_loss: 0.0799 - val_auc_2: 0.9956 - lr: 3.4300e-04\n",
      "Epoch 103/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0566 - auc_2: 0.9978 - val_loss: 0.0787 - val_auc_2: 0.9956 - lr: 3.4300e-04\n",
      "Epoch 104/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0565 - auc_2: 0.9978 - val_loss: 0.0784 - val_auc_2: 0.9957 - lr: 3.4300e-04\n",
      "Epoch 105/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0565 - auc_2: 0.9978 - val_loss: 0.0787 - val_auc_2: 0.9957 - lr: 3.4300e-04\n",
      "Epoch 106/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0564 - auc_2: 0.9978 - val_loss: 0.0786 - val_auc_2: 0.9957 - lr: 3.4300e-04\n",
      "Epoch 107/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0563 - auc_2: 0.9978 - val_loss: 0.0787 - val_auc_2: 0.9956 - lr: 3.4300e-04\n",
      "Epoch 108/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0562 - auc_2: 0.9978 - val_loss: 0.0787 - val_auc_2: 0.9956 - lr: 3.4300e-04\n",
      "Epoch 109/400\n",
      "350/352 [============================>.] - ETA: 0s - loss: 0.0562 - auc_2: 0.9978\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0562 - auc_2: 0.9978 - val_loss: 0.0788 - val_auc_2: 0.9956 - lr: 3.4300e-04\n",
      "Epoch 110/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0555 - auc_2: 0.9978 - val_loss: 0.0786 - val_auc_2: 0.9957 - lr: 2.4010e-04\n",
      "Epoch 111/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0555 - auc_2: 0.9978 - val_loss: 0.0786 - val_auc_2: 0.9957 - lr: 2.4010e-04\n",
      "Epoch 112/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0554 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9956 - lr: 2.4010e-04\n",
      "Epoch 113/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0553 - auc_2: 0.9979 - val_loss: 0.0787 - val_auc_2: 0.9956 - lr: 2.4010e-04\n",
      "Epoch 114/400\n",
      "350/352 [============================>.] - ETA: 0s - loss: 0.0553 - auc_2: 0.9979\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0553 - auc_2: 0.9979 - val_loss: 0.0789 - val_auc_2: 0.9956 - lr: 2.4010e-04\n",
      "Epoch 115/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0549 - auc_2: 0.9979 - val_loss: 0.0785 - val_auc_2: 0.9956 - lr: 1.6807e-04\n",
      "Epoch 116/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0548 - auc_2: 0.9979 - val_loss: 0.0785 - val_auc_2: 0.9957 - lr: 1.6807e-04\n",
      "Epoch 117/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0548 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9956 - lr: 1.6807e-04\n",
      "Epoch 118/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0547 - auc_2: 0.9979 - val_loss: 0.0789 - val_auc_2: 0.9956 - lr: 1.6807e-04\n",
      "Epoch 119/400\n",
      "346/352 [============================>.] - ETA: 0s - loss: 0.0546 - auc_2: 0.9979\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0546 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9957 - lr: 1.6807e-04\n",
      "Epoch 120/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0543 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 121/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0543 - auc_2: 0.9979 - val_loss: 0.0785 - val_auc_2: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 122/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0542 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 123/400\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0542 - auc_2: 0.9979 - val_loss: 0.0788 - val_auc_2: 0.9957 - lr: 1.1765e-04\n",
      "Epoch 124/400\n",
      "346/352 [============================>.] - ETA: 0s - loss: 0.0542 - auc_2: 0.9979Restoring model weights from the end of the best epoch: 104.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.0542 - auc_2: 0.9979 - val_loss: 0.0786 - val_auc_2: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 124: early stopping\n",
      "The val auc for fold 0, Dense_model_3 is 0.9962407730809923\n",
      "Fitting fold 1 for Dense_model_3...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1482\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1480'>1481</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1481'>1482</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1482'>1483</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1483'>1484</a>\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3708'>3709</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3709'>3710</a>\u001b[0m \u001b[39mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3710'>3711</a>\u001b[0m \u001b[39mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3713'>3714</a>\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3714'>3715</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3715'>3716</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3716'>3717</a>\u001b[0m \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3700'>3701</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3702'>3703</a>\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3703'>3704</a>\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3704'>3705</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/generic.py?line=3705'>3706</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:897\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/internals/managers.py?line=895'>896</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis]\n\u001b[1;32m--> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/internals/managers.py?line=896'>897</a>\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/internals/managers.py?line=898'>899</a>\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:292\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers/utils.py?line=290'>291</a>\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers/utils.py?line=291'>292</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindices are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers/utils.py?line=292'>293</a>\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\kaggle_tabular_playground_2022_05\\get_test_predictions.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000007?line=0'>1</a>\u001b[0m preds \u001b[39m=\u001b[39m test_predictor(model_3, X_train, y_train, X_test, n_folds \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\kaggle_tabular_playground_2022_05\\get_test_predictions.ipynb Cell 9'\u001b[0m in \u001b[0;36mtest_predictor\u001b[1;34m(model_in, X_train, y_train, X_test, n_folds)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mclone_model(model_in)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=17'>18</a>\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mAUC()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=18'>19</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=20'>21</a>\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39;49miloc[train_idx], X_train\u001b[39m.\u001b[39miloc[val_idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=21'>22</a>\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39miloc[train_idx], y_train\u001b[39m.\u001b[39miloc[val_idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=24'>25</a>\u001b[0m     X_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=25'>26</a>\u001b[0m     y_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=32'>33</a>\u001b[0m     ],\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/kaggle_tabular_playground_2022_05/get_test_predictions.ipynb#ch0000006?line=33'>34</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=965'>966</a>\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=966'>967</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1511\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1508'>1509</a>\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1509'>1510</a>\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1510'>1511</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_list_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1512'>1513</a>\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1513'>1514</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1514'>1515</a>\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32mc:\\Users\\ruair\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1485\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1481'>1482</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1482'>1483</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1483'>1484</a>\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/ruair/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexing.py?line=1484'>1485</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "preds = test_predictor(model_3, X_train, y_train, X_test, n_folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "sub['state'] = preds.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('data/submissions'):\n",
    "    os.mkdir('data/submissions')\n",
    "\n",
    "sub.to_csv('data/submissions/nn_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "748e94d17ea178bd88fa7222e32cd8a3aee3702bf3f6a8e8cbd3fee18cb98607"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
